{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from chapter4.gpt_implementation import GTPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define GPT2 config\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTPModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GTPModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define text to token ids and other way round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text is: 'Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren'\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model, \n",
    "    idx=text_to_token_ids(text = start_context, tokenizer=tokenizer), \n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text is: '{token_ids_to_text(token_ids=token_ids, tokenizer=tokenizer)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], [40, 1107, 588]])  # [\"every effort moves\",  #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345], [1107, 588, 11311]])  # [\" effort moves you\",  #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)  # Probability of each token in vocabulary\n",
    "print(probas.shape)  # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 100)\n",
    "y = torch.log(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48725.8672)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../chapter2/the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        # Create list of input tokens\n",
    "        self.input_ids = []\n",
    "        # Create list of output tokens\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the training loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"increase the `training_ratio`\"\n",
    "    )\n",
    "\n",
    "if total_tokens * (1 - train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the validation loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"decrease the `training_ratio`\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.981104850769043\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "# else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device)  # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123)  # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad():  # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \" f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.820, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.338\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.624, Val loss 7.050\n",
      "Ep 2 (Step 000015): Train loss 6.049, Val loss 6.603\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.559, Val loss 6.494\n",
      "Ep 3 (Step 000025): Train loss 5.428, Val loss 6.384\n",
      "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4 (Step 000030): Train loss 4.974, Val loss 6.285\n",
      "Ep 4 (Step 000035): Train loss 4.721, Val loss 6.303\n",
      "Every effort moves you of the picture.      \"I                \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 4.058, Val loss 6.159\n",
      "Every effort moves you know the                          \"Oh, and the fact a little the latter the honour his pictures--and it's--I he had\n",
      "Ep 6 (Step 000045): Train loss 3.676, Val loss 6.174\n",
      "Ep 6 (Step 000050): Train loss 3.117, Val loss 6.148\n",
      "Every effort moves you know the fact, and pushed one of the to the fact of the last word.        \"Oh, and I was his pictures--I had the donkey. I had the donkey. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 3.026, Val loss 6.182\n",
      "Ep 7 (Step 000060): Train loss 2.281, Val loss 6.145\n",
      "Every effort moves you know,\" was not that the picture.  I-chairs forward. \"There: \"Yes, and!  \"I didn't say, and I was a little. \"I he was his pictures--because he was his pictures\n",
      "Ep 8 (Step 000065): Train loss 1.863, Val loss 6.164\n",
      "Ep 8 (Step 000070): Train loss 1.532, Val loss 6.259\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, and Mrs. I remember getting off a prod, as once one had been the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.181, Val loss 6.249\n",
      "Ep 9 (Step 000080): Train loss 0.900, Val loss 6.266\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the honour being _mine_--because he's. The\n",
      "Ep 10 (Step 000085): Train loss 0.658, Val loss 6.369\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GTPModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    #plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we put model into eval mode and transfer it into eval model, therefore some layers like drop out would be deactivated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTPModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer=tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids=token_ids, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)  # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f\"Temperature = {T}\")\n",
    "\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1], input=torch.tensor(float(\"-inf\")), other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to go a hint a littleoms he painted with a single enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTPModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GTPModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GTPModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 11:43:13.129644: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-02 11:43:13.147096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735814593.162828   11748 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735814593.167444   11748 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-02 11:43:13.188687: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
    "# Source for \"Build a Large Language Model From Scratch\"\n",
    "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
    "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
    "\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\",\n",
    "        \"encoder.json\",\n",
    "        \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\",\n",
    "        \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\",\n",
    "        \"vocab.bpe\",\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # Get the total file size from headers, defaulting to 0 if not present\n",
    "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "            # Check if file exists and has the same size\n",
    "            if os.path.exists(destination):\n",
    "                file_size_local = os.path.getsize(destination)\n",
    "                if file_size == file_size_local:\n",
    "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                    return\n",
    "\n",
    "            # Define the block size for reading the file\n",
    "            block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "            # Initialize the progress bar with total file size\n",
    "            progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "                # Open the destination file in binary write mode\n",
    "                with open(destination, \"wb\") as file:\n",
    "                    # Read the file in chunks and write to destination\n",
    "                    while True:\n",
    "                        chunk = response.read(block_size)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))  # Update progress bar\n",
    "    except urllib.error.HTTPError:\n",
    "        s = (\n",
    "            f\"The specified URL ({url}) is incorrect, the internet connection cannot be established,\"\n",
    "            \"\\nor the requested file is temporarily unavailable.\\nPlease visit the following website\"\n",
    "            \" for help: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
    "        )\n",
    "        print(s)\n",
    "\n",
    "\n",
    "# Alternative way using `requests`\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 90.3kiB/s]\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:01<00:00, 1.01MiB/s]\n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 188kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [06:50<00:00, 1.21MiB/s]  \n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 12.1MiB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:00<00:00, 718kiB/s] \n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 647kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTPModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GTPModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTPModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something happens\n",
      "\n",
      "This would remove you from a battle\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5,\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
